# Linear-regression
In this notebook, we provide practical applications of linear models in Machine Learning such as : Ordinary Least Squares estimator, Ridge, Lasso and PCA. We provide as well some useful algorithms such as Forward Variable Selection which aims at selecting the most important features of the dataset, and which is coded from scratch in this notebook.
We use also the Sequential Feature Selector from the sklearn library to do the same task as the Forward Variable selection, and we compare their results.
We coded as well the crossvalidation algorithm from scratch to perform the same crossvalidation as of the sklearn.
This notebook is organized as follows:

### 1 - Preprocessing: Scaling and OLS
### 2 - Forward Variable Selection
### 3 - OLS with selected features
### 4 - Sequential Feature Selector
### 5 - Ridge
### 6 - Lasso
### 7 - Crossvalidation and Elastic Net
### 8 - Bootstrap
### 9 - PCA
