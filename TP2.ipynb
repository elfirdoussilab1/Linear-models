{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnyJps8K6wHi"
   },
   "source": [
    "# TP 2: Aymane El Firdoussi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IXUFA2am6x64"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "# imports go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ypO4yAYK7DpI"
   },
   "outputs": [],
   "source": [
    "fn1 = \"Aymane\"\n",
    "ln1 = \"El Firdoussi\"\n",
    "filename = \"_\".join(map(lambda s: s.strip().lower(),\n",
    "                      [\"SD-TSIA204_lab2\", ln1, fn1])) + \".ipynb\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsSsfFpp9Qo2"
   },
   "source": [
    "## Question 1: Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEyJ7iFe9fOv"
   },
   "source": [
    "### 1-a) Fixing the random seed to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0FcLGqy-9Uru"
   },
   "outputs": [],
   "source": [
    "# Setting the random seed to 0\n",
    "random.seed(0)\n",
    "\n",
    "# Therefore, we will always get the same random value if we compute: random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBLqS_uX-ZfH"
   },
   "source": [
    "### 1-b) Loading the data and printing means and standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kLIhFyjz-Gdt",
    "outputId": "56a480ca-7436-4f4f-bbde-2596a68fc292"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1       2.808561\n",
       "V2       2.811137\n",
       "V3       2.813727\n",
       "V4       2.816363\n",
       "V5       2.819098\n",
       "          ...    \n",
       "V97      3.081070\n",
       "V98      3.062290\n",
       "V99      3.043548\n",
       "V100     3.024895\n",
       "fat     18.142326\n",
       "Length: 101, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data:\n",
    "data = pd.read_csv(\"meatspec.csv\")\n",
    "\n",
    "#printing the mean of each covariate\n",
    "data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hnnohIhm-tGV",
    "outputId": "cba524d5-0c12-41ad-ea6f-b607d45209e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1       0.410793\n",
       "V2       0.413352\n",
       "V3       0.415906\n",
       "V4       0.418465\n",
       "V5       0.421040\n",
       "          ...    \n",
       "V97      0.539730\n",
       "V98      0.538586\n",
       "V99      0.537108\n",
       "V100     0.535354\n",
       "fat     12.740297\n",
       "Length: 101, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the standard deviation of each covariate:\n",
    "data.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRPVRhnS_gHa"
   },
   "source": [
    "#### The data is not centered since the mean is different from 0, nor it is standardized since standard deviations are not equal to 1. And all our data is not normalized since the values are not between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUkIxaqhHXV4"
   },
   "source": [
    "## 1-c) Separating the data into train and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lzJExcC-_e_0"
   },
   "outputs": [],
   "source": [
    "# The import of train_test_split has been done in the first cell\n",
    "X = data.drop(['fat'], axis=1)\n",
    "y= data['fat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "# The import of standard scaler has been done as well in the first cell\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_train_scaled = scaler.fit_transform(y_train.to_numpy().reshape(-1,1))\n",
    "y_test_scaled = scaler.transform(y_test.to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQxdesVjPt7R",
    "outputId": "13a05bdb-7632-4519-e82a-29eaf72abf90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if data is correctly standardized or not:\n",
    "X_train_scaled.std()\n",
    "#y_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3fPIqFXKLxC"
   },
   "source": [
    "## 1-d) Fitting a regular OLS:\n",
    "The regular OLS is given by: \n",
    "$$ \\theta = (X^TX)^{-1}X^T Y$$\n",
    "We don't need to fit the intercept since the data is centered.\n",
    "We can also use the Linear Regression model from the sklean.linear_model library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIvlStTMKM9C",
    "outputId": "9f588629-0650-4e1b-936e-efef6c12b659"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing the regular OLS estimator:\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "\n",
    "# We fit the model to the training set\n",
    "reg = model.fit(X_train_scaled,y_train_scaled)\n",
    "\n",
    "# Prediction phase (test phase)\n",
    "y_pred = reg.predict(X_test_scaled)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aY_b-Wk-UFd4"
   },
   "source": [
    "#### 1-e) Computing the $R^2$ coefficients :\n",
    "The $R^2$ can be calculated as follows:\n",
    " $$ R^2 = 1 - \\frac{\\| \\hat{Y} - Y \\|}{\\| Y - \\bar{y}_n \\mathbb{1}_n\\|} $$\n",
    "\n",
    " Where $ \\hat{Y} $ is the predicted vector using our model, and $\\mathbb{1}_n$ is the mean of the test vector y_test_scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "_qojTOr3MBq2",
    "outputId": "7ba51bb5-e8fd-4cd8-be87-e8f65e735a7e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             R2\n",
       "model          \n",
       "1      0.997417"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing the R^2 coefficient for this OLS\n",
    "def R2(y, y_pred):\n",
    "    Y_bar = np.mean(y)\n",
    "    SSR = np.sum((y_pred - y) ** 2)\n",
    "    SST = np.sum((y - Y_bar) ** 2)\n",
    "    return 1 - SSR / SST\n",
    "    \n",
    "R2 = reg.score(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Storing it into a dataframe\n",
    "d = {'model': [1], 'R2': [R2]}\n",
    "df_coef = pd.DataFrame(data=d).set_index('model')\n",
    "df_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5uVEHHtXpjV"
   },
   "source": [
    "## Question 2: Forward variable selection\n",
    "\n",
    "The OLS $\\theta_n(Y,\\tilde{X_k}) = \\arg \\min_{(\\theta_0, \\theta_1) \\in \\mathbb{R}^2} \\| Y - \\theta_0 \\mathbb{1}_n - \\theta_1 \\tilde{X_k}\\|^2 = \\arg \\min_{\\theta \\in \\mathbb{R}^2} \\| Y  -  X_k \\theta\\|^2 $ , where $ X_k = (\\mathbb{1}_n,\\tilde{X_k})$ is given by: (differentiating and finding the zero of the derivative)\n",
    "$$ \\theta_n(Y,\\tilde{X_k}) = (X_k^T X_k)^{-1}X_k^T Y$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YNWTCgdxUad2"
   },
   "outputs": [],
   "source": [
    "# Define the statistic\n",
    "def T(Y,X,k,n): # Y is a column vector, whereas X is our matrix\n",
    "    Xk = X[:,k].reshape(-1,1)\n",
    "    reg = LinearRegression().fit(Xk,Y)\n",
    "    teta_n = reg.coef_[0]\n",
    "    # inverse of Gram matrix\n",
    "    G_1 = np.linalg.inv(Xk.T @ Xk)\n",
    "    s_n = np.sqrt(G_1[0,0])\n",
    "    sigma_n = (1/np.sqrt(n-2)) * np.linalg.norm(Y - reg.predict(Xk), 2) \n",
    "    return teta_n / (s_n * sigma_n)\n",
    "\n",
    "# Forward variable selection algorithm\n",
    "def forward_var_selection(X,Y): # X is a matrix, Y column vector and A the set of all columns of X\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    r = Y.copy() \n",
    "    S = {} # the set of ordered features that we will get at the end, here it is a dictionary\n",
    "    p_values = [] # the list of p-values\n",
    "\n",
    "    #define the set of features\n",
    "    A = list(range(0, p))\n",
    "\n",
    "    while len(A) > 0 : \n",
    "        # Computing tests for all features\n",
    "        values = np.zeros(p)\n",
    "       \n",
    "        for i in A : # columns left in A\n",
    "            values[i] = abs(T(r, X, i, n))\n",
    "        \n",
    "        k_max = np.argmax(values)\n",
    "        # computing the p-value associated with the value max\n",
    "        p_value = 2*(1 - norm.cdf(abs(values[k_max])))\n",
    "        p_values.append(p_value)\n",
    "\n",
    "        # Adding the feature the maximizes the test T to S\n",
    "        X_max = X[:, k_max].reshape(-1, 1)\n",
    "        reg = LinearRegression().fit(X_max, r)\n",
    "        S[k_max] = values[k_max]\n",
    "        r = r - reg.predict(X_max)\n",
    "        del A[A.index(k_max)]\n",
    "    \n",
    "    return S, p_values\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "tGNXHXf-hV2l",
    "outputId": "b7d015fb-42dc-4d54-c245-bccdca68dbae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>V41</td>\n",
       "      <td>7.105427e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>V8</td>\n",
       "      <td>2.220204e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>V40</td>\n",
       "      <td>2.395152e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>V7</td>\n",
       "      <td>2.448525e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>V42</td>\n",
       "      <td>2.639340e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature       p_value\n",
       "index                      \n",
       "40        V41  7.105427e-14\n",
       "7          V8  2.220204e-02\n",
       "39        V40  2.395152e-02\n",
       "6          V7  2.448525e-02\n",
       "41        V42  2.639340e-02"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing the data to use in forward variable selection\n",
    "S,p_values = forward_var_selection(X_train_scaled,y_train_scaled) # 40, 7, 39, 6\n",
    "\n",
    "# Now since features of our dataset are written as V'number +1', then we do the following\n",
    "def features(l):\n",
    "    V = []\n",
    "    for i in l:\n",
    "        V.append('V' + str(i + 1))\n",
    "    return V \n",
    "\n",
    "# DataFrame with features and p values\n",
    "d = {'index':S.keys(), 'feature': features(S.keys()), 'p_value': p_values}\n",
    "df_var_sel = pd.DataFrame(data=d).set_index('index')\n",
    "df_var_sel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-a) Applying the OLS to features that have p value smaller than 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 7, 39, 6, 41, 8, 38, 5, 42, 9, 37, 4]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting features with p value smaller than 0.05\n",
    "mask = (df_var_sel['p_value'] < 0.05)\n",
    "selected = df_var_sel.loc[mask].index.to_list()\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying OLS\n",
    "reg = LinearRegression().fit(X_train_scaled[:,selected], y_train_scaled)\n",
    "y_pred2 = reg.predict(X_test_scaled[:,selected])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-b) Computing the $R^2$ coefficient for this model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 coefficient using sklearn\n",
    "R2 = reg.score(X_train_scaled[:,selected], y_train_scaled)\n",
    "#new_row = pd.Series([2, R2], index=['model', 'p_value'])\n",
    "df_coef.loc[2] = [R2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.964785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             R2\n",
       "model          \n",
       "1      0.997417\n",
       "2      0.964785"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Sequential Feature Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 17, 21, 40, 48, 52, 57, 60, 90, 96, 98, 99]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the sequential feature selctor from sklearn.feature_selection\n",
    "reg = LinearRegression()\n",
    "sfs = SequentialFeatureSelector(reg, n_features_to_select = len(selected), direction = 'forward')\n",
    "sfs.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Returning the selected features\n",
    "selected_sfs = [i for i, x in enumerate(sfs.get_support()) if x == True]\n",
    "selected_sfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "We observe that the features selected by the SequentialFeatureSelector are not all the same as the ones chosen with the Forward Variable Selection algorithm. Which was expected since the stopping criterion is different in both methods. \n",
    "In fact, for the Forward Variable selection, the stopping criterion that we chose is the p value of the statistical test, which is not so accurate since we are using an asymptotical behaviour of the test, hence we need more data to be more accurate. Whereas the SequentialFeatureSelector compares the score for each possible feature addition or removal, and selects the one that results in the best improvement of the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the $R^2$ score for this new feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying OLS of new features\n",
    "reg = LinearRegression().fit(X_train_scaled[:,selected_sfs], y_train_scaled)\n",
    "y_pred3 = reg.predict(X_test_scaled[:,selected_sfs])\n",
    "\n",
    "# R2 coefficient using sklearn\n",
    "R2 = reg.score(X_train_scaled[:,selected_sfs], y_train_scaled)\n",
    "\n",
    "# Adding the new value to the dataFrame df_coef\n",
    "df_coef.loc[3] = [R2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.964785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.969018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             R2\n",
       "model          \n",
       "1      0.997417\n",
       "2      0.964785\n",
       "3      0.969018"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "We observe that the $R^2$ score for both methods are so close, and that they have similar performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ridge estimator is the solution of the following optimization problem:\n",
    "$$ \\hat{\\theta}_n = \\arg \\min_{\\theta \\in \\mathbb{R}^p} \\| Y - X\\theta\\|^2 + \\alpha \\| \\theta \\|^2 $$\n",
    "The function to minimize is $ \\alpha $-strongly convex, hence the solution to this problem is unique and is given by:\n",
    "$$ \\hat{\\theta}_n = (X^T X + \\alpha I_p)^{-1} X^T Y$$\n",
    "Where $X \\in \\mathbb{R}^{n x p}$ and $ Y \\in \\mathbb{R}^n $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programming the ridge estimator\n",
    "def Ridge(X,Y,alpha):\n",
    "    p = x.shape[1]\n",
    "    return np.linalg.inv( (X.T @ X) + alpha* np.ones((p,p))) @ X.T @ Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of values of alpha\n",
    "alpha = linspace(1e-9, 100,  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
